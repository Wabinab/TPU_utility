{"cells":[{"cell_type":"code","execution_count":0,"outputs":[],"metadata":{"collapsed":false,"_kg_hide-input":false},"source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:30:54.407515Z\",\"iopub.execute_input\":\"2021-08-13T07:30:54.407964Z\",\"iopub.status.idle\":\"2021-08-13T07:30:54.418185Z\",\"shell.execute_reply.started\":\"2021-08-13T07:30:54.407874Z\",\"shell.execute_reply\":\"2021-08-13T07:30:54.417044Z\"}}\ndef setup_kaggle():\n    os.system(\"curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\")\n    print(\"Download complete\")\n    os.system(\"python pytorch-xla-env-setup.py --version 1.7 --apt-packages libomp5 libopenblas-dev\")\n    print(\"Setup complete\")\n    \n    clear_output()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:30:54.419785Z\",\"iopub.execute_input\":\"2021-08-13T07:30:54.420081Z\",\"iopub.status.idle\":\"2021-08-13T07:32:03.078556Z\",\"shell.execute_reply.started\":\"2021-08-13T07:30:54.420055Z\",\"shell.execute_reply\":\"2021-08-13T07:32:03.077446Z\"}}\nimport os\nfrom IPython.display import clear_output\n\ntry: import torch_xla\nexcept Exception: setup_kaggle()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T08:25:16.666039Z\",\"iopub.execute_input\":\"2021-08-13T08:25:16.666464Z\",\"iopub.status.idle\":\"2021-08-13T08:25:17.674989Z\",\"shell.execute_reply.started\":\"2021-08-13T08:25:16.666429Z\",\"shell.execute_reply\":\"2021-08-13T08:25:17.674029Z\"}}\nimport copy\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport torch_xla  # as a decoration here. \nimport torch_xla.core.xla_model as xm\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.utils as xu\nimport torch_xla.utils.cached_dataset as xcd\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as D\nfrom torch.optim import lr_scheduler\n\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\n\nfrom sklearn.metrics import f1_score\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:32:03.740759Z\",\"iopub.execute_input\":\"2021-08-13T07:32:03.741070Z\",\"iopub.status.idle\":\"2021-08-13T07:32:03.755591Z\",\"shell.execute_reply.started\":\"2021-08-13T07:32:03.741041Z\",\"shell.execute_reply\":\"2021-08-13T07:32:03.754013Z\"}}\ndef dataloader(train_ds, val_ds, flags, distributed=False):\n    \"\"\"\n    flags requirement: (python dict)\n        \"bs\": (int) batch_size,\n        \"num_workers\": (int) number of workers.\n    \"\"\"\n    if distributed:\n        train_sampler = D.distributed.DistributedSampler(\n            train_ds, num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(), shuffle=True)\n        train_loader = D.DataLoader(train_ds, batch_size=flags[\"bs\"], sampler=train_sampler,\n                                   num_workers=flags[\"num_workers\"], drop_last=True)\n    else:\n        train_loader = D.DataLoader(train_ds, batch_size=flags[\"bs\"], shuffle=True,\n                                   num_workers=flags[\"num_workers\"], drop_last=False)\n        \n    val_loader = D.DataLoader(val_ds, batch_size=flags[\"bs\"], shuffle=False,\n                             num_workers=flags[\"num_workers\"],\n                             drop_last=True if distributed else False)\n    \n    return {\"train\": train_loader, \"val\": val_loader}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:32:03.756846Z\",\"iopub.execute_input\":\"2021-08-13T07:32:03.757120Z\",\"iopub.status.idle\":\"2021-08-13T07:32:03.767000Z\",\"shell.execute_reply.started\":\"2021-08-13T07:32:03.757095Z\",\"shell.execute_reply\":\"2021-08-13T07:32:03.766009Z\"}}\ndef distrib_dataloader(get_dataset, flags, cached=False):\n    \"\"\"\n    get_dataset: (function) The function that returns train_ds, val_ds as tuple. \n    flags: (python dict): Requires: \n        \"bs\": (int) batch_size,\n        \"num_workers\": (int) number of workers.\n    \"\"\"\n    serial_exec = xmp.MpSerialExecutor()\n    \n    train_ds, val_ds = serial_exec.run(get_dataset)\n    dls = dataloader(train_ds, val_ds, flags, distributed=True)\n    return dls\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:32:03.768730Z\",\"iopub.execute_input\":\"2021-08-13T07:32:03.769260Z\",\"iopub.status.idle\":\"2021-08-13T07:32:03.781067Z\",\"shell.execute_reply.started\":\"2021-08-13T07:32:03.769218Z\",\"shell.execute_reply\":\"2021-08-13T07:32:03.780241Z\"}}\ndef train_cycle_distrib(dls, flags, train_loop_fn, val_loop_fn, device=None):\n    \"\"\"\n    dls: dataloaders, use distrib_dataloader() to get this. \n    flags: (python dict). Required:\n        \"num_epochs\": number of epochs to train for. \n        \"metrics_debug\": whether to print metrics report of TPU. \n    train_loop_fn: (function) The training loop function.\n    val_loop_fn: (function) The validation loop function. \n    device = device. Defaults: xm.xla_device()\n    \"\"\"\n    for epoch in range(1, flags[\"num_epochs\"] + 1):\n        para_loader = pl.ParallelLoader(dls[\"train\"], [device])\n        train_loop_fn(para_loader.per_device_loader(device))\n        clear_output(wait=True)\n        xm.master_print(f\"Finished training epoch {epoch}\")\n\n        para_loader = pl.ParallelLoader(dls[\"val\"], [device])\n        returned_val = test_loop_fn(para_loader.per_device_loader(device))\n        if flags[\"metrics_debug\"]: xm.master_print(met.metrics_report(), flush=True)\n        \n    return returned_val\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:32:03.782583Z\",\"iopub.execute_input\":\"2021-08-13T07:32:03.783117Z\",\"iopub.status.idle\":\"2021-08-13T07:32:03.791108Z\",\"shell.execute_reply.started\":\"2021-08-13T07:32:03.783077Z\",\"shell.execute_reply\":\"2021-08-13T07:32:03.790281Z\"}}\ndef cached_dataset(cache_train_loc=None, cache_val_loc=None):\n    \"\"\"\n    NOTE: This SHOULD BE CALLED inside the `_mp_fn` function of distributed. \n    Will fetch the cached dataset that is already preprocessed. \n    \"\"\"\n    if cache_train_loc is None: cache_train_loc = \"./cache_train\"\n    if cache_val_loc is None: cache_val_loc = \"./cache_val\"\n        \n    train_ds = xcd.CachedDataset(None, cache_train_loc)\n    val_ds = xcd.CachedDataset(None, cache_val_loc)\n    \n    return train_ds, val_ds\n\n# %% [markdown]\n# # LR Finder TPU\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:32:03.793573Z\",\"iopub.execute_input\":\"2021-08-13T07:32:03.793988Z\",\"iopub.status.idle\":\"2021-08-13T07:32:03.807096Z\",\"shell.execute_reply.started\":\"2021-08-13T07:32:03.793949Z\",\"shell.execute_reply\":\"2021-08-13T07:32:03.805659Z\"}}\nclass LinearScheduler(lr_scheduler._LRScheduler):\n    \"\"\"\n    Linearly increases lr between two boundaries over a number of iterations. \n    \"\"\"\n    def __init__(self, opt, end_lr, num_iter):  # original `optimizer`\n        self.end_lr = end_lr\n        self.num_iter = num_iter\n        super(LinearScheduler, self).__init__(opt)\n        \n    def get_lr(self):\n        \"\"\"Formula: start + pct * (end - start)\"\"\"\n        curr_iter = self.last_epoch + 1\n        pct = curr_iter / self.num_iter  # ratio\n        return [base_lr + pct * (self.end_lr - base_lr) for base_lr in self.base_lrs]\n    \n    \nclass ExponentialScheduler(lr_scheduler._LRScheduler):\n    \"\"\"\n    Exponentially increases lr between two boundaries over a number of iterations. \n    \"\"\"\n    def __init__(self, opt, end_lr, num_iter, last_epoch = -1):\n        self.end_lr = end_lr\n        self.num_iter = num_iter\n        super(ExponentialScheduler, self).__init__(opt, last_epoch=last_epoch) ## \n        \n    def get_lr(self):\n        curr_iter = self.last_epoch + 1\n        pct = curr_iter / self.num_iter\n        return [base_lr * (self.end_lr / base_lr) ** pct for base_lr in self.base_lrs]\n    \n    \nclass CosineScheduler(lr_scheduler._LRScheduler):\n    \"\"\"\n    Cosine increases lr between two boundaries over a number of iterations. \n    \"\"\"\n    def __init__(self, opt, end_lr, num_iter, last_epoch = -1):\n        self.end_lr = end_lr\n        self.num_iter = num_iter\n        super(CosineScheduler, self).__init__(opt, last_epoch=last_epoch) ## \n        \n    def get_lr(self):\n        curr_iter = self.last_epoch + 1\n        pct = curr_iter / self.num_iter\n        cos_out = np.cos(np.pi * pct) + 1\n        return [self.end_lr + (base_lr - self.end_lr) / 2 * cos_out for base_lr in self.base_lrs]\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:51:49.119992Z\",\"iopub.execute_input\":\"2021-08-13T07:51:49.120494Z\",\"iopub.status.idle\":\"2021-08-13T07:51:49.145708Z\",\"shell.execute_reply.started\":\"2021-08-13T07:51:49.120439Z\",\"shell.execute_reply\":\"2021-08-13T07:51:49.144652Z\"}}\nclass LRFinder:\n    \n    def __init__(self, model, opt, criterion, start_lr=1e-7, device=None):\n        self.model = copy.deepcopy(model)\n        self.opt = opt\n        self.criterion = criterion\n        \n        # Save model initial dict\n#         self.save_file = Path(\"./\")\n#         torch.save(self.model, self.save_file)\n        \n        if device is None: self.device = next(model.parameters()).device\n        else: self.device = device\n            \n        self.model.to(self.device)\n        \n        self.history = {\"lr\": [], \"losses\": []}\n        \n        for l in self.opt.param_groups:\n            l[\"initial_lr\"] = start_lr\n            \n    def reset(self):\n        \"\"\"Resets model to initial state.\"\"\"\n#         self.model = torch.load(self.save_file)\n#         self.model.train()\n#         self.save_file.unlink()\n#         return self.model\n        return None\n    \n    def calculate_smoothing_value(self, beta):\n        n, mov_avg = 0, 0\n        while True:\n            n += 1\n            value = yield\n            mov_avg = beta * mov_avg + (1 - beta) * value\n            smooth = mov_avg / (1 - beta**n)\n            yield smooth\n            \n    def lr_find(self, train_loader, end_lr=10, num_iter=150, step_mode=\"exp\", \n               loss_smoothing_beta=0.99, diverge_th=5, device=None):\n        \"\"\"\n        Performs LR Find test\n        \n        :args:\n            train_loader: data loader. \n            end_lr: maximum lr to stop. \n            num_iter: max iterations.\n            step_mode: anneal function. Default 'exp'. Choices 'linear', 'cos'. \n            loss_smoothing_beta: loss smoothing factor. Range: [0, 1)\n            diverge_th: max loss value after which training should be stopped. \n            device: device\n        \"\"\"\n        if device is not None: self.device = device\n        \n        # Reset test results\n        self.history = {\"lr\": [], \"losses\": []}\n        self.best_loss = None\n        self.smoothener = self.calculate_smoothing_value(loss_smoothing_beta)\n        \n        choices = {\n            \"exp\": ExponentialScheduler,\n            \"cos\": CosineScheduler,\n            \"linear\": LinearScheduler\n        }\n        \n        try: lr_scheduler = choices[step_mode.lower()](self.opt, end_lr, num_iter)\n        except KeyError: \n            raise ValueError(f\"Expected mode 'exp', 'cos', or 'linear'; got {step_mode}\")\n            \n        if 0 < loss_smoothing_beta >= 1:\n            raise ValueError(\"loss_smoothing_beta outside range [0, 1).\")\n            \n        iterator = iter(train_loader)\n        for each_iter in tqdm(range(num_iter)):\n            try: data, target = next(iterator)\n            except StopIteration: \n                iterator = iter(train_loader)\n                data, target = next(iterator)\n                \n            loss = self._train_batch(data, target.to(torch.float32))\n            \n            # Update learning rate\n            lr_scheduler.step()\n            self.history[\"lr\"].append(lr_scheduler.get_lr()[0])\n            \n            # Track best loss and smooth if loss_smoothing_beta is specified.\n            if each_iter == 0: self.best_loss = loss\n            else:\n                next(self.smoothener)\n                self.best_loss = self.smoothener.send(loss)\n                if loss < self.best_loss: self.best_loss = loss\n                    \n            # Check if loss diverged. If it does, stop the test.\n            self.history[\"losses\"].append(loss)\n            if loss > diverge_th * self.best_loss:\n                break\n                \n                \n        clear_output()\n        print(f\"Best loss: {self.best_loss}\")\n        steepest = self.steepest_lr()\n        print(f\"Steepest point: {steepest}\")\n        self._plot()\n        model = self.reset()\n        \n        return steepest, model, self.best_loss\n        \n    def _train_batch(self, data, target):\n        self.model.train()  # training mode\n        data, target = data.to(self.device), target.to(self.device)\n        \n        # Forward pass\n        self.opt.zero_grad()\n        output = self.model(data)\n        loss = self.criterion(output, target)\n        \n        # Backward pass\n        loss.backward()\n        if self.device.type == \"xla\": xm.optimizer_step(self.opt, barrier=True)\n        else: self.opt.step()\n        \n        return loss.item()\n    \n    def _plot(self):\n        losses = self.history[\"losses\"]\n        lr = self.history[\"lr\"]\n        \n        plt.figure(dpi=120)\n        plt.semilogx(lr, losses)\n        plt.xlabel(\"Learning Rate\")\n        plt.ylabel(\"Losses\")\n        plt.grid()\n        plt.show()\n    \n    def steepest_lr(self):\n        losses = np.array(self.history[\"losses\"])\n        lr = np.array(self.history[\"lr\"])\n        return lr[np.argmax(losses[:-1] - losses[1:])]\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:52:31.990760Z\",\"iopub.execute_input\":\"2021-08-13T07:52:31.991354Z\",\"iopub.status.idle\":\"2021-08-13T07:52:31.996891Z\",\"shell.execute_reply.started\":\"2021-08-13T07:52:31.991293Z\",\"shell.execute_reply\":\"2021-08-13T07:52:31.996033Z\"}}\ndef lr_finder(model, opt, criterion, dls, device):\n    \"\"\"\n    Learning Rate Finder with default values. \n    model: your model.\n    opt: torch.optim optimizers.\n    criterion: torch.nn loss function. \n    dls: dataloaders. Check out `dataloader` function. \n    device: device.\n    \n    Return: steepest_point, model, best_loss\n    \"\"\"\n    lrfinder = LRFinder(model, opt, criterion, device=device)\n    return lrfinder.lr_find(dls[\"train\"])\n\n# %% [markdown]\n# # One Cycle Policy\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:53:04.364632Z\",\"iopub.execute_input\":\"2021-08-13T07:53:04.365059Z\",\"iopub.status.idle\":\"2021-08-13T07:53:04.372010Z\",\"shell.execute_reply.started\":\"2021-08-13T07:53:04.365022Z\",\"shell.execute_reply\":\"2021-08-13T07:53:04.370905Z\"}}\nclass Stepper():\n    \"\"\"Step through n_iter on a schedule defined by func.\"\"\"\n    def __init__(self, val, n_iter: int, func):\n        self.start, self.end = val\n        self.n_iter = max(1, n_iter)\n        self.func = func\n        self.n = 0\n        \n    def step(self):\n        \"\"\"Returned next value along annealed schedule.\"\"\"\n        self.n += 1\n        return self.func(self.start, self.end, self.n/self.n_iter)\n    \n    @property\n    def is_done(self):\n        \"\"\"Return True if schedule complted.\"\"\"\n        return self.n >= self.n_iter\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-08-13T07:53:08.882115Z\",\"iopub.execute_input\":\"2021-08-13T07:53:08.882454Z\",\"iopub.status.idle\":\"2021-08-13T07:53:08.888884Z\",\"shell.execute_reply.started\":\"2021-08-13T07:53:08.882424Z\",\"shell.execute_reply\":\"2021-08-13T07:53:08.887981Z\"}}\ndef annealing_no(start, end, pct):\n    \"\"\"No annealing, always return 'start'.\"\"\"\n    return start\n\n\ndef annealing_linear(start, end, pct):\n    \"\"\"Linearly anneal from start to end as pct goes from 0.0 to 1.0.\"\"\"\n    return start + pct * (end - start)\n\n\ndef annealing_exp(start, end, pct):\n    \"\"\"Exponentially anneal from start to end as pct goes from 0.0 to 1.0.\"\"\"\n    return start * (end / start) ** pct\n\n\ndef annealing_cos(start, end, pct):\n    \"\"\"Cosine anneal from start and end as pct goes from 0.0 to 1.0.\"\"\"\n    cos_out = np.cos(np.pi * pct) + 1\n    return end + (start - end) / 2 * cos_out\n\n# %% [code]\nclass OneCyclePolicy_TPU:\n    def __init__(self, model, opt, criterion, FLAGS, num_iter=None, train_ds=None,\n                 momentum=(0.95, 0.85), div_factor=25, pct_start=0.4,\n                train_transform=None, val_transform=None, channels_last=True,\n                get_dataset=None, cache_train_loc=None, cache_val_loc=None):\n        \"\"\"\n        :args:\n        \n        model: model.\n        opt: optimizer.\n        criterion: loss function. \n        FLAGS: (python dict) FLAGS containing information to pass in. Refer to FLAGS tutorial\n             on what's required to put inside flag. \n        num_iter: (int) number of iterations. please use len(train_dataset) // batch_size\n        train_ds: (IF num_iter IS NONE): (PyTorch Dataset) pass in training dataset. \n        momentum: Default: (0.95, 0.85)  # momentum for optimizer.\n        div_factor: (int) Minimum learning rate: max_learning_rate / div_factor. \n        pct_start: (float) starting percentage. \n        device:\n        train_transform: Not used. \n        val_transform: Not used. \n        channels_last: (bool) Whether to have NHWC instead of NCHW format. \n        get_dataset: (python function). Should returns train_ds, val_ds. Required if \n            you don't define cache_train_loc and cache_val_loc. \n        \"\"\"\n        self.SERIAL_EXEC = xmp.MpSerialExecutor()\n        self.WRAPPED_MODEL = xmp.MpModelWrapper(model)\n        self.opt = opt\n        self.criterion = criterion\n        self.flags = FLAGS\n        self.chls = channels_last\n        self.get_dataset = get_dataset\n        self.cache_train_loc = cache_train_loc\n        self.cache_val_loc = cache_val_loc\n        \n        if get_dataset is cache_train_loc is None:\n            assert os.path.exists(\"./cache_train\"), \"Folder does not exist. Please put cached train dataset in this folder.\"\n        if get_dataset is cache_val_loc is None:\n            assert os.path.exists(\"./cache_val\"), \"Folder does not exist. Please put cached val dataset in this folder.\"\n        \n        if num_iter is train_ds is None: \n            raise ValueError(\"One of num_iter or train_ds must be defined\")\n        if num_iter is None: num_iter = len(train_ds) // self.flags[\"bs\"]\n        \n        n = num_iter * self.flags[\"num_epochs\"]\n        a1 = int(n * pct_start)\n        a2 = n - a1\n        self.phases = ((a1, annealing_linear), (a2, annealing_cos))\n        \n        self.lr_scheds = None\n        self.mom_scheds = None\n        self.idx_s = 0\n        \n        self.div_factor = div_factor\n        self.momentum = momentum\n        \n\n        # Future development\n        self.train_transform = train_transform\n        self.val_transform = val_transform\n        \n    def steps(self, *steps):\n        \"\"\"Build anneal schedule for all of the parameters. \"\"\"\n        return [Stepper(step, n_iter, func=func)\n               for (step, (n_iter, func)) in zip(steps, self.phases)]\n    \n    def after_lrfind_define(self, max_lr):\n        max_lr = max_lr * xm.xrt_world_size()\n        min_lr = max_lr / self.div_factor\n        self.lr_scheds = self.steps((min_lr, max_lr), (max_lr, min_lr / 1e4))\n        self.mom_scheds = self.steps(self.momentum, self.momentum[::-1])\n        self.update_lr_mom(self.lr_scheds[0].start, self.mom_scheds[0].start)\n        \n    def update_lr_mom(self, lr=0.001, mom=0.99):\n        for l in self.opt.param_groups:\n            l[\"lr\"] = lr\n            \n            if isinstance(self.opt, (torch.optim.Adamax, torch.optim.Adam)):\n                l[\"betas\"] = (mom, 0.999)\n            elif isinstance(self.opt, torch.optim.SGD):\n                l[\"momentum\"] = mom\n    \n    def train_tpu(self, train_ds, val_ds):\n        torch.manual_seed(self.flags[\"seed\"])\n        \n        if train_ds is None: train_ds, val_ds = self.SERIAL_EXEC.run(get_dataset)\n        dls = dataloader(train_ds, val_ds, self.flags, distributed=True)\n        \n        device = xm.xla_device()\n        model = self.WRAPPED_MODEL.to(device)\n        \n        lrfinder = LRFinder(model, self.opt, self.criterion)\n        steepest, _, best_loss = self.SERIAL_EXEC.run(lambda: lrfinder.lr_find(dls[\"train\"]))\n#         model = model.to(device)\n        \n        self.after_lrfind_define(steepest)\n        \n        def train_loop_fn(loader):\n            tracker = xm.RateTracker()\n            model.train()\n            \n            running_loss = 0.0\n            total_samples = 0\n            \n            for data, target in tqdm(loader):\n                self.opt.zero_grad()\n                data, target = data.to(device), target.to(device)\n                if self.chls: data = data.to(memory_format=torch.channels_last)\n                \n                output = model(data)\n                loss = self.criterion(output, target.to(torch.float32))\n#                 preds = (torch.sigmoid(output).data > 0.5).to(torch.float32)\n                \n                loss.backward()\n                xm.optimizer_step(self.opt)\n                self.update_lr_mom(self.lr_scheds[self.idx_s].step(),\n                                    self.mom_scheds[self.idx_s].step())\n                            \n                if self.lr_scheds[self.idx_s].is_done: self.idx_s += 1\n                tracker.add(self.flags[\"bs\"])\n                \n                running_loss += loss.item() * data.size(0)\n                total_samples += data.size(0)\n\n            return running_loss, total_samples\n            \n        def test_loop_fn(loader):\n            total_samples = 0\n            running_loss, f1Score = 0.0, 0.0\n            model.eval()\n            \n            for data, target in tqdm(loader):\n                data, target = data.to(device), target.to(device)\n                \n                output = model(data)\n                loss = self.criterion(output, target.to(torch.float32))\n                preds = (torch.sigmoid(output).data > 0.5).to(torch.float32)\n                \n                total_samples += data.size(0)\n                running_loss += loss.item() * data.size(0)\n                \n                target = target.cpu().to(torch.int).numpy()\n                preds = preds.cpu().to(torch.int).numpy()\n                \n                f1Score += f1_score(target, preds, average=\"weighted\") * data.size(0)\n                \n            epoch_loss = running_loss / total_samples\n            epoch_f1score = f1Score / total_samples\n            \n#             print(f\"\"\"\n#                 Val loss: {epoch_loss} | \n#                 Val F1Score: {epoch_f1score} | \n#             \"\"\", flush=True)\n            return epoch_loss, epoch_f1score, data, preds, target\n        \n        for epoch in range(1, self.flags[\"num_epochs\"] + 1):\n            para_loader = pl.ParallelLoader(dls[\"train\"], [device])\n            running_loss, total_samples = train_loop_fn(para_loader.per_device_loader(device))\n            clear_output(wait=True)\n            xm.master_print(f\"Finished training epoch {epoch}\")\n            xm.master_print(f\"Train loss: {running_loss / total_samples}\", flush=True)\n            \n            para_loader = pl.ParallelLoader(dls[\"val\"], [device])\n            test_loss, f1score, data, pred, targ = test_loop_fn(\n                                    para_loader.per_device_loader(device))\n            xm.master_print(f\"\"\"\n                Val loss: {test_loss} | \n                Val F1Score: {f1score} | \n            \"\"\", flush=True)\n            if self.flags[\"metrics_debug\"]: xm.master_print(met.metrics_report(), flush=True)\n                \n        return test_loss, f1score, data, pred, targ, model\n    \n    def _mp_fn(self, rank):\n        flags = self.flags\n        torch.set_default_tensor_type(torch.FloatTensor)\n        \n        if self.get_dataset is None: \n            train_ds, val_ds = cached_dataset(self.cache_train_loc, self.cache_val_loc)\n        else: train_ds, val_ds = None, None\n            \n        loss, f1score, data, pred, targ, model = self.train_tpu(train_ds, val_ds)\n        if rank == 0: torch.save(model.state_dict(), self.flags[\"save_path\"])\n            \n    def train(self):\n        import gc\n        gc.collect()\n        try:\n            xmp.spawn(self._mp_fn, args=(), nprocs=self.flags[\"num_cores\"], start_method=\"fork\")\n        except Exception: \n            print(\"\"\"\n                xm.xla_device() had been defined previously hence you see the above error.\n                I killed the kernel for you. Please run Jupyter kernel from the beginning.\n                If jupyter kernel killed failed, please restart jupyter kernel yourself.\n                On extreme cases, please use \"factory reset\" (available on Colab and Kaggle).\n                In other cases, please check you have not called xm.xla_device() in previous cells.\n                Note: xm.xla_device() can only be called once per kernel lifetime to use \n                    multiple TPU cores. \n            \"\"\")\n            os._exit(00)\n            \n\n# %% [markdown]\n# `weighted` can result in F-score **that is not between precision and recall**. URL: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n\n# %% [code]\n"}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}